{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define virality (label)\n",
    "Meme is labeled 1, viral, if it's score is in the top 5% of memes posted with in the +/- 7 day period around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over18</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>ocr_raw</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.02.15_288</td>\n",
       "      <td>211152</td>\n",
       "      <td>1642</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/n4ildkpurph61.png</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Wait I didn't mean it like that</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>a man with a hat and a beard standing in front...</td>\n",
       "      <td>Wait I didn't mean it like that - High schoole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.10.20_959</td>\n",
       "      <td>207206</td>\n",
       "      <td>811</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/gsqgq6uwuau51.jpg</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Don't be mad</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>a couple of white dogs standing next to each o...</td>\n",
       "      <td>Don't be mad - @ renk. 5\\n@ 1 Award\\n\\nI'm a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.01.18_675</td>\n",
       "      <td>207066</td>\n",
       "      <td>1734</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/eg4t9kvlplb41.jpg</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>For real tho</td>\n",
       "      <td>...</td>\n",
       "      <td>a cartoon of a cat with a box on its back</td>\n",
       "      <td>For real tho -                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.06.09_755</td>\n",
       "      <td>187936</td>\n",
       "      <td>743</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/1wniz8ionv351.jpg</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>Right as rain after that</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>a bunch of legos that are sitting on top of ea...</td>\n",
       "      <td>Right as rain after that - — :\\nMy stomach hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.07.08_336</td>\n",
       "      <td>182056</td>\n",
       "      <td>616</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/nrj9smsfek951.jpg</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Licensed Dad Joke</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>a collage of pictures of a dog wearing a birth...</td>\n",
       "      <td>Licensed Dad Joke - Dads telling jokes at home...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   score  num_comments  over18   \n",
       "0  2021.02.15_288  211152          1642   False  \\\n",
       "1  2020.10.20_959  207206           811   False   \n",
       "2  2020.01.18_675  207066          1734   False   \n",
       "3  2020.06.09_755  187936           743   False   \n",
       "4  2020.07.08_336  182056           616   False   \n",
       "\n",
       "                                   url       date   \n",
       "0  https://i.redd.it/n4ildkpurph61.png 2021-02-15  \\\n",
       "1  https://i.redd.it/gsqgq6uwuau51.jpg 2020-10-20   \n",
       "2  https://i.redd.it/eg4t9kvlplb41.jpg 2020-01-18   \n",
       "3  https://i.redd.it/1wniz8ionv351.jpg 2020-06-09   \n",
       "4  https://i.redd.it/nrj9smsfek951.jpg 2020-07-08   \n",
       "\n",
       "                         title_raw   \n",
       "0  Wait I didn't mean it like that  \\\n",
       "1                     Don't be mad   \n",
       "2                     For real tho   \n",
       "3         Right as rain after that   \n",
       "4                Licensed Dad Joke   \n",
       "\n",
       "                                             ocr_raw   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                         caption_raw   \n",
       "0  a man with a hat and a beard standing in front...  \\\n",
       "1  a couple of white dogs standing next to each o...   \n",
       "2          a cartoon of a cat with a box on its back   \n",
       "3  a bunch of legos that are sitting on top of ea...   \n",
       "4  a collage of pictures of a dog wearing a birth...   \n",
       "\n",
       "                                            all_text  \n",
       "0  Wait I didn't mean it like that - High schoole...  \n",
       "1  Don't be mad - @ renk. 5\\n@ 1 Award\\n\\nI'm a d...  \n",
       "2  For real tho -                                ...  \n",
       "3  Right as rain after that - — :\\nMy stomach hur...  \n",
       "4  Licensed Dad Joke - Dads telling jokes at home...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data\n",
    "memes_data = pd.read_json('./Data/Memes/memesfinal.json')\n",
    "memes_data = memes_data.loc[:, ~memes_data.columns.str.contains('^Unnamed')]\n",
    "memes_data['date'] = memes_data.id.str[:10]\n",
    "memes_data['date'] = pd.to_datetime(memes_data['date'])\n",
    "\n",
    "print(len(memes_data))\n",
    "memes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 899525/899525 [2:42:21<00:00, 92.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>date</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125964</td>\n",
       "      <td>2018.01.01_71</td>\n",
       "      <td>66</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438307</td>\n",
       "      <td>2018.01.01_142</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438305</td>\n",
       "      <td>2018.01.01_53</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>438304</td>\n",
       "      <td>2018.01.01_129</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>438303</td>\n",
       "      <td>2018.01.01_122</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index              id  score       date  viral\n",
       "0  125964   2018.01.01_71     66 2018-01-01    0.0\n",
       "1  438307  2018.01.01_142      1 2018-01-01    0.0\n",
       "2  438305   2018.01.01_53      1 2018-01-01    0.0\n",
       "3  438304  2018.01.01_129      1 2018-01-01    0.0\n",
       "4  438303  2018.01.01_122      1 2018-01-01    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add viral column \n",
    "# meme is considered viral if its score in the top 5% of memes posted that week\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_score = memes_data[['id','score','date']]\n",
    "df_score = df_score.sort_values(by='date', ascending=True)\n",
    "df_score.reset_index(inplace=True)\n",
    "df_score['viral'] = np.nan\n",
    "\n",
    "# save one of each date that occurs in df in order to find date range +/-7 around each date ignoring missing values\n",
    "meme_dates = []\n",
    "start = True\n",
    "for date in df_score.date:\n",
    "    current = date\n",
    "    if start == True:\n",
    "        meme_dates.append(date)\n",
    "        previous = date\n",
    "        start = False\n",
    "    elif current != previous:\n",
    "        meme_dates.append(date)\n",
    "        previous = date\n",
    "        \n",
    "# get viral feature\n",
    "for i in tqdm(range(0,len(df_score))):\n",
    "    # get date range +/- 7 days around date of current record\n",
    "    cur_date_idx = meme_dates.index(df_score.at[i,'date'])\n",
    "    if cur_date_idx-7 < 0: # edge case\n",
    "        begin_range = meme_dates[0]\n",
    "        end_range = meme_dates[14]\n",
    "    elif cur_date_idx+7 >= len(meme_dates): # edge case\n",
    "        begin_range = meme_dates[len(meme_dates)-15]\n",
    "        end_range = meme_dates[len(meme_dates)-1]\n",
    "    else:\n",
    "        begin_range = meme_dates[cur_date_idx-7]\n",
    "        end_range = meme_dates[cur_date_idx+7]\n",
    "    # crop df based on this date range and get 95th quantile\n",
    "    quantile = df_score[df_score.date.between(begin_range, end_range)].score.quantile(0.95)\n",
    "    # if the score of current record is greater than this append 1 else append 0\n",
    "    if df_score.at[i,'score'] >= quantile:\n",
    "        df_score.at[i,'viral'] = 1\n",
    "    else:\n",
    "        df_score.at[i,'viral'] = 0\n",
    "\n",
    "df_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save data\n",
    "save = df_score[['id','viral']]\n",
    "save.to_json('./results/processed_features/viral_05.json')\n",
    "len(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using log upvotes for analysis, we could use a normalized upvotes feature: upvote / mean_upvote_that_week. NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a normalized upvotes column: upvote/avg_upvote_in_week_around_meme\n",
    "import numpy as np\n",
    "\n",
    "# here's a score df to work with (summed score for each date in our time period)\n",
    "df_score = memes_data[['id','score','date']]\n",
    "df_score = pd.DataFrame(df_score.groupby(df_score.date).score.sum()); df_score.reset_index(inplace=True)\n",
    "df_count = memes_data[['id','date']]\n",
    "df_count = pd.DataFrame(df_count.groupby(df_count.date).id.count()); df_count.reset_index(inplace=True)\n",
    "df = df_score.merge(df_count,on='date'); df = df.rename({'id':'count_memes','score':'sum_score'}, axis=1)\n",
    "df.index = pd.DatetimeIndex(df.date)\n",
    "df = df.drop(['date'],axis=1)\n",
    "\n",
    "# calculate rolling sum score over week\n",
    "rolling_score = df.rolling('7D').sum_score.sum() #.resample('W').mean()\n",
    "rolling_count = df.rolling('7D').count_memes.sum()\n",
    "df = df.merge(rolling_score, on='date'); df = df.merge(rolling_count, on='date')\n",
    "df = df.rename({'sum_score_x':'sum_score','count_memes_x':'count_memes','sum_score_y':'rolling_week_score','count_memes_y':'rolling_week_count'}, axis=1)\n",
    "\n",
    "# function sums the 7 days prior to the date, manually replace score for the first 7 days with that of the 7th day\n",
    "df.at['2014-01-01', 'rolling_week_count'] = 102; df.at['2014-01-02', 'rolling_week_count'] = 102; df.at['2014-01-03', 'rolling_week_count'] = 102; df.at['2014-01-04', 'rolling_week_count'] = 102; df.at['2014-01-05', 'rolling_week_count'] = 102; df.at['2014-01-06', 'rolling_week_count'] = 102;\n",
    "df.at['2014-01-01', 'rolling_week_score'] = 3782; df.at['2014-01-02', 'rolling_week_score'] = 3782; df.at['2014-01-03', 'rolling_week_score'] = 3782; df.at['2014-01-04', 'rolling_week_score'] = 3782; df.at['2014-01-05', 'rolling_week_score'] = 3782; df.at['2014-01-06', 'rolling_week_score'] = 3782;\n",
    "df['rolling_week_avg'] = df['rolling_week_score']/df['rolling_week_count']\n",
    "df[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
