{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General script for cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, timeit\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over18</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>ocr_raw</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>all_text</th>\n",
       "      <th>processed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.02.15_288</td>\n",
       "      <td>211152</td>\n",
       "      <td>1642</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/n4ildkpurph61.png</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Wait I didn't mean it like that</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>a man with a hat and a beard standing in front...</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>[wait, didnt, mean, like, high, schooler, kill...</td>\n",
       "      <td>[wait, didnt, mean, like, high, schooler, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.10.20_959</td>\n",
       "      <td>207206</td>\n",
       "      <td>811</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/gsqgq6uwuau51.jpg</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Don't be mad</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>a couple of white dogs standing next to each o...</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>[dont, mad, renk, award, dude, fucking, hate, ...</td>\n",
       "      <td>[dont, mad, renk, award, dude, fuck, hate, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.01.18_675</td>\n",
       "      <td>207066</td>\n",
       "      <td>1734</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/eg4t9kvlplb41.jpg</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>For real tho</td>\n",
       "      <td>...</td>\n",
       "      <td>a cartoon of a cat with a box on its back</td>\n",
       "      <td>...</td>\n",
       "      <td>[real, tho, cartoon, cat, box, back]</td>\n",
       "      <td>[real, tho, cartoon, cat, box, back]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.06.09_755</td>\n",
       "      <td>187936</td>\n",
       "      <td>743</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/1wniz8ionv351.jpg</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>Right as rain after that</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>a bunch of legos that are sitting on top of ea...</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>[right, rain, stomach, hurt, it’s, probably, g...</td>\n",
       "      <td>[right, rain, stomach, hurt, it’, probabl, gho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.07.08_336</td>\n",
       "      <td>182056</td>\n",
       "      <td>616</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/nrj9smsfek951.jpg</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Licensed Dad Joke</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>a collage of pictures of a dog wearing a birth...</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>[licensed, dad, joke, dad, telling, joke, home...</td>\n",
       "      <td>[licens, dad, joke, dad, tell, joke, home, dad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   score  num_comments  over18   \n",
       "0  2021.02.15_288  211152          1642   False  \\\n",
       "1  2020.10.20_959  207206           811   False   \n",
       "2  2020.01.18_675  207066          1734   False   \n",
       "3  2020.06.09_755  187936           743   False   \n",
       "4  2020.07.08_336  182056           616   False   \n",
       "\n",
       "                                   url       date   \n",
       "0  https://i.redd.it/n4ildkpurph61.png 2021-02-15  \\\n",
       "1  https://i.redd.it/gsqgq6uwuau51.jpg 2020-10-20   \n",
       "2  https://i.redd.it/eg4t9kvlplb41.jpg 2020-01-18   \n",
       "3  https://i.redd.it/1wniz8ionv351.jpg 2020-06-09   \n",
       "4  https://i.redd.it/nrj9smsfek951.jpg 2020-07-08   \n",
       "\n",
       "                         title_raw   \n",
       "0  Wait I didn't mean it like that  \\\n",
       "1                     Don't be mad   \n",
       "2                     For real tho   \n",
       "3         Right as rain after that   \n",
       "4                Licensed Dad Joke   \n",
       "\n",
       "                                             ocr_raw   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                         caption_raw   \n",
       "0  a man with a hat and a beard standing in front...  \\\n",
       "1  a couple of white dogs standing next to each o...   \n",
       "2          a cartoon of a cat with a box on its back   \n",
       "3  a bunch of legos that are sitting on top of ea...   \n",
       "4  a collage of pictures of a dog wearing a birth...   \n",
       "\n",
       "                                            all_text   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                           processed   \n",
       "0  [wait, didnt, mean, like, high, schooler, kill...  \\\n",
       "1  [dont, mad, renk, award, dude, fucking, hate, ...   \n",
       "2               [real, tho, cartoon, cat, box, back]   \n",
       "3  [right, rain, stomach, hurt, it’s, probably, g...   \n",
       "4  [licensed, dad, joke, dad, telling, joke, home...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [wait, didnt, mean, like, high, schooler, kill...  \n",
       "1  [dont, mad, renk, award, dude, fuck, hate, peo...  \n",
       "2               [real, tho, cartoon, cat, box, back]  \n",
       "3  [right, rain, stomach, hurt, it’, probabl, gho...  \n",
       "4  [licens, dad, joke, dad, tell, joke, home, dad...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_json(\"./Data/Memes/memesfinal_processed.json\")\n",
    "#df = df[df.date.between('2014-01-01', '2022-11-15')]\n",
    "df['all_text'] = df['ocr_raw'] + ' ' + df['title_raw'] #+ ' ' + df['caption_raw']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00\n",
      "2022-11-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "least_recent_date = df['date'].min(); print(least_recent_date)\n",
    "most_recent_date = df['date'].max(); print(most_recent_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column for processing text\n",
    "df['processed'] = df['all_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYT only: replace \"G.O.P.\" type abreviations before removing punctuation\n",
    "processed = []\n",
    "\n",
    "for test_str in df['processed']:\n",
    "    test_str = test_str + ' '\n",
    "    while(test_str.find('.')>0):\n",
    "        period = test_str.find('.')\n",
    "        if test_str[period+1].isalpha():\n",
    "            test_str = test_str[0:period] + test_str[period+1:len(test_str)]\n",
    "        else:\n",
    "            test_str = test_str[0:period] + ' ' + test_str[period+1:len(test_str)]\n",
    "    processed.append(test_str)\n",
    "df['processed'] = processed \n",
    "\n",
    "# NYT: replace NYT \n",
    "df['processed'] = df['processed'].str.replace(\"New York Times\", \"NYT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace anything that is not a letter or number with a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].str.replace(\"\\n\", \" \") # this is for the ocr feature which returns \\n chars\n",
    "df['processed'] = df['processed'].str.replace(\"'s\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].str.replace(\"[^a-zA-Z]+\", \" \") #nyt_df[column].map(lambda x: re.sub('[,\\.!?]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].str.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make everything lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].map(lambda x: x.lower()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove words less than 3 letters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional stopwords to remove if desired\n",
    "remove = ['ahead','yet','two','first','like','say','make','would','get','could','may','even','use','call','month',\n",
    "         'week','day','want','need','long','come','three','also','know','made','see','monday','tuesday','wednesday',\n",
    "         'thursday','friday','saturday','sunday','still','more','find','good','found','set','sinc','turn','place',\n",
    "         'four','anoth','next','thing','second','well','five','ago','today','keep','go','put','among','think', 'new',\n",
    "         'happen','seem','other','without','hour','word','tell','let','six','away','becam','leav','begin','time',\n",
    "          'said','told']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/katebarnes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|█████████████████████████████████| 899525/899525 [02:36<00:00, 5748.40it/s]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words.extend(remove) # no additional stopwords were removed from memes data\n",
    "tokenized_list_of_words = []\n",
    "\n",
    "for i in tqdm(range(0, len(df))):\n",
    "    l1 = df['processed'].iloc[i]\n",
    "    tokenized_list_of_words.append([word for word in l1 if word not in stop_words])\n",
    "    \n",
    "df['processed'] = tokenized_list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace specific words to improve the vocabulary agreement between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 899525/899525 [00:38<00:00, 23485.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# MEMES: if 'real' is not followed by 'estate' replace with 'actual'\n",
    "updated_words = []\n",
    "sublist = []\n",
    "found = False\n",
    "\n",
    "for l1 in tqdm(df['processed']):\n",
    "    sublist = []\n",
    "    for word in l1:\n",
    "        if found==True:\n",
    "            if word=='estate':\n",
    "                sublist.append('real')\n",
    "            else:\n",
    "                sublist.append('actual')\n",
    "            found = False\n",
    "        if word=='real':\n",
    "            found=True\n",
    "            continue\n",
    "        sublist.append(word)\n",
    "    updated_words.append([sublist])\n",
    "    \n",
    "df['processed'] = updated_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmetize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/katebarnes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "100%|█████████████████████████████████| 899525/899525 [01:58<00:00, 7615.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_list_of_words = []\n",
    "\n",
    "for i in tqdm(range(0, len(df))):\n",
    "    l1 = tokenized_list_of_words[i]\n",
    "    lemma_list_of_words.append([lemmatizer.lemmatize(word) for word in l1])\n",
    "\n",
    "df['processed'] = lemma_list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stem words to but store in a separate column just in case overstemming is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 899525/899525 [04:44<00:00, 3164.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemma_list_of_words = []\n",
    "\n",
    "for i in tqdm(range(0, len(df))):\n",
    "    l1 = lemma_list_of_words[i]\n",
    "    stemma_list_of_words.append([stemmer.stem(word) for word in l1])\n",
    "    \n",
    "df['stemmed'] = stemma_list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look into most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data = [' '.join(rec) for rec in df.stemmed]\n",
    "data_set = ' '.join(data)\n",
    "\n",
    "# split() returns list of all the words in the string\n",
    "split_it = data_set.split()\n",
    "\n",
    "# Pass the split_it list to instance of Counter class.\n",
    "Counters_found = Counter(split_it)\n",
    "\n",
    "# most_common() produces k frequently encountered\n",
    "# input values and their respective counts.\n",
    "most_occur = Counters_found.most_common(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('take', 21879),\n",
       " ('messag', 21694),\n",
       " ('come', 21613),\n",
       " ('wear', 21155),\n",
       " ('got', 21108),\n",
       " ('friend', 21098),\n",
       " ('kid', 20932),\n",
       " ('boy', 20845),\n",
       " ('first', 20720),\n",
       " ('bunch', 20623),\n",
       " ('men', 20608),\n",
       " ('glass', 20207),\n",
       " ('beard', 20068),\n",
       " ('gun', 20024),\n",
       " ('back', 20003),\n",
       " ('anoth', 19246),\n",
       " ('photo', 19109),\n",
       " ('old', 19100),\n",
       " ('coupl', 19037),\n",
       " ('everi', 18914)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_occur[80:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-combine tokens into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    stemma_list_of_words[i] = ' '.join(stemma_list_of_words[i])\n",
    "    \n",
    "df['stemmed']= stemma_list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over18</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>ocr_raw</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>all_text</th>\n",
       "      <th>processed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.02.15_288</td>\n",
       "      <td>211152</td>\n",
       "      <td>1642</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/n4ildkpurph61.png</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Wait I didn't mean it like that</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>a man with a hat and a beard standing in front...</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>[high, schooler, kill, college, tuition, milit...</td>\n",
       "      <td>high schooler kill colleg tuition militari rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.10.20_959</td>\n",
       "      <td>207206</td>\n",
       "      <td>811</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/gsqgq6uwuau51.jpg</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Don't be mad</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>a couple of white dogs standing next to each o...</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>[renk, award, dude, fucking, hate, people, tel...</td>\n",
       "      <td>renk award dude fuck hate peopl tell look tire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.01.18_675</td>\n",
       "      <td>207066</td>\n",
       "      <td>1734</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/eg4t9kvlplb41.jpg</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>For real tho</td>\n",
       "      <td>...</td>\n",
       "      <td>a cartoon of a cat with a box on its back</td>\n",
       "      <td>...</td>\n",
       "      <td>[real, tho]</td>\n",
       "      <td>real tho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.06.09_755</td>\n",
       "      <td>187936</td>\n",
       "      <td>743</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/1wniz8ionv351.jpg</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>Right as rain after that</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>a bunch of legos that are sitting on top of ea...</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>[stomach, hurt, it’s, probably, ghost, ri, any...</td>\n",
       "      <td>stomach hurt it’ probabl ghost ri anyway here’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.07.08_336</td>\n",
       "      <td>182056</td>\n",
       "      <td>616</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/nrj9smsfek951.jpg</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Licensed Dad Joke</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>a collage of pictures of a dog wearing a birth...</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>[dad, telling, joke, home, dad, cling, work, “...</td>\n",
       "      <td>dad tell joke home dad cling work “et licens d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   score  num_comments  over18   \n",
       "0  2021.02.15_288  211152          1642   False  \\\n",
       "1  2020.10.20_959  207206           811   False   \n",
       "2  2020.01.18_675  207066          1734   False   \n",
       "3  2020.06.09_755  187936           743   False   \n",
       "4  2020.07.08_336  182056           616   False   \n",
       "\n",
       "                                   url       date   \n",
       "0  https://i.redd.it/n4ildkpurph61.png 2021-02-15  \\\n",
       "1  https://i.redd.it/gsqgq6uwuau51.jpg 2020-10-20   \n",
       "2  https://i.redd.it/eg4t9kvlplb41.jpg 2020-01-18   \n",
       "3  https://i.redd.it/1wniz8ionv351.jpg 2020-06-09   \n",
       "4  https://i.redd.it/nrj9smsfek951.jpg 2020-07-08   \n",
       "\n",
       "                         title_raw   \n",
       "0  Wait I didn't mean it like that  \\\n",
       "1                     Don't be mad   \n",
       "2                     For real tho   \n",
       "3         Right as rain after that   \n",
       "4                Licensed Dad Joke   \n",
       "\n",
       "                                             ocr_raw   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                         caption_raw   \n",
       "0  a man with a hat and a beard standing in front...  \\\n",
       "1  a couple of white dogs standing next to each o...   \n",
       "2          a cartoon of a cat with a box on its back   \n",
       "3  a bunch of legos that are sitting on top of ea...   \n",
       "4  a collage of pictures of a dog wearing a birth...   \n",
       "\n",
       "                                            all_text   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                           processed   \n",
       "0  [high, schooler, kill, college, tuition, milit...  \\\n",
       "1  [renk, award, dude, fucking, hate, people, tel...   \n",
       "2                                        [real, tho]   \n",
       "3  [stomach, hurt, it’s, probably, ghost, ri, any...   \n",
       "4  [dad, telling, joke, home, dad, cling, work, “...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  high schooler kill colleg tuition militari rec...  \n",
       "1  renk award dude fuck hate peopl tell look tire...  \n",
       "2                                           real tho  \n",
       "3  stomach hurt it’ probabl ghost ri anyway here’...  \n",
       "4  dad tell joke home dad cling work “et licens d...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = df[['id','stemmed']]\n",
    "save.to_json('./Data/Memes/memesfinal_processed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over18</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>ocr_raw</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>all_text</th>\n",
       "      <th>processed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.02.15_288</td>\n",
       "      <td>211152</td>\n",
       "      <td>1642</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/n4ildkpurph61.png</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Wait I didn't mean it like that</td>\n",
       "      <td>High schooler: I'd kill for\\ncollege tuition\\n...</td>\n",
       "      <td>a man with a hat and a beard standing in front...</td>\n",
       "      <td>Wait I didn't mean it like that - High schoole...</td>\n",
       "      <td>[wait, didnt, mean, like, high, schooler, kill...</td>\n",
       "      <td>[wait, didnt, mean, like, high, schooler, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.10.20_959</td>\n",
       "      <td>207206</td>\n",
       "      <td>811</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/gsqgq6uwuau51.jpg</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Don't be mad</td>\n",
       "      <td>@ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...</td>\n",
       "      <td>a couple of white dogs standing next to each o...</td>\n",
       "      <td>Don't be mad - @ renk. 5\\n@ 1 Award\\n\\nI'm a d...</td>\n",
       "      <td>[dont, mad, renk, award, dude, fucking, hate, ...</td>\n",
       "      <td>[dont, mad, renk, award, dude, fuck, hate, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.01.18_675</td>\n",
       "      <td>207066</td>\n",
       "      <td>1734</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/eg4t9kvlplb41.jpg</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>For real tho</td>\n",
       "      <td>...</td>\n",
       "      <td>a cartoon of a cat with a box on its back</td>\n",
       "      <td>For real tho -                                ...</td>\n",
       "      <td>[real, tho, cartoon, cat, box, back]</td>\n",
       "      <td>[real, tho, cartoon, cat, box, back]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.06.09_755</td>\n",
       "      <td>187936</td>\n",
       "      <td>743</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/1wniz8ionv351.jpg</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>Right as rain after that</td>\n",
       "      <td>— :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...</td>\n",
       "      <td>a bunch of legos that are sitting on top of ea...</td>\n",
       "      <td>Right as rain after that - — :\\nMy stomach hur...</td>\n",
       "      <td>[right, rain, stomach, hurt, it’s, probably, g...</td>\n",
       "      <td>[right, rain, stomach, hurt, it’, probabl, gho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.07.08_336</td>\n",
       "      <td>182056</td>\n",
       "      <td>616</td>\n",
       "      <td>False</td>\n",
       "      <td>https://i.redd.it/nrj9smsfek951.jpg</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Licensed Dad Joke</td>\n",
       "      <td>Dads telling jokes at home\\n\\nDads cling es a ...</td>\n",
       "      <td>a collage of pictures of a dog wearing a birth...</td>\n",
       "      <td>Licensed Dad Joke - Dads telling jokes at home...</td>\n",
       "      <td>[licensed, dad, joke, dad, telling, joke, home...</td>\n",
       "      <td>[licens, dad, joke, dad, tell, joke, home, dad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   score  num_comments  over18   \n",
       "0  2021.02.15_288  211152          1642   False  \\\n",
       "1  2020.10.20_959  207206           811   False   \n",
       "2  2020.01.18_675  207066          1734   False   \n",
       "3  2020.06.09_755  187936           743   False   \n",
       "4  2020.07.08_336  182056           616   False   \n",
       "\n",
       "                                   url       date   \n",
       "0  https://i.redd.it/n4ildkpurph61.png 2021-02-15  \\\n",
       "1  https://i.redd.it/gsqgq6uwuau51.jpg 2020-10-20   \n",
       "2  https://i.redd.it/eg4t9kvlplb41.jpg 2020-01-18   \n",
       "3  https://i.redd.it/1wniz8ionv351.jpg 2020-06-09   \n",
       "4  https://i.redd.it/nrj9smsfek951.jpg 2020-07-08   \n",
       "\n",
       "                         title_raw   \n",
       "0  Wait I didn't mean it like that  \\\n",
       "1                     Don't be mad   \n",
       "2                     For real tho   \n",
       "3         Right as rain after that   \n",
       "4                Licensed Dad Joke   \n",
       "\n",
       "                                             ocr_raw   \n",
       "0  High schooler: I'd kill for\\ncollege tuition\\n...  \\\n",
       "1  @ renk. 5\\n@ 1 Award\\n\\nI'm a dude, and | fuck...   \n",
       "2                                                ...   \n",
       "3  — :\\nMy stomach hurts Bo i\\n\\n/@\\nIt’s probabl...   \n",
       "4  Dads telling jokes at home\\n\\nDads cling es a ...   \n",
       "\n",
       "                                         caption_raw   \n",
       "0  a man with a hat and a beard standing in front...  \\\n",
       "1  a couple of white dogs standing next to each o...   \n",
       "2          a cartoon of a cat with a box on its back   \n",
       "3  a bunch of legos that are sitting on top of ea...   \n",
       "4  a collage of pictures of a dog wearing a birth...   \n",
       "\n",
       "                                            all_text   \n",
       "0  Wait I didn't mean it like that - High schoole...  \\\n",
       "1  Don't be mad - @ renk. 5\\n@ 1 Award\\n\\nI'm a d...   \n",
       "2  For real tho -                                ...   \n",
       "3  Right as rain after that - — :\\nMy stomach hur...   \n",
       "4  Licensed Dad Joke - Dads telling jokes at home...   \n",
       "\n",
       "                                           processed   \n",
       "0  [wait, didnt, mean, like, high, schooler, kill...  \\\n",
       "1  [dont, mad, renk, award, dude, fucking, hate, ...   \n",
       "2               [real, tho, cartoon, cat, box, back]   \n",
       "3  [right, rain, stomach, hurt, it’s, probably, g...   \n",
       "4  [licensed, dad, joke, dad, telling, joke, home...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [wait, didnt, mean, like, high, schooler, kill...  \n",
       "1  [dont, mad, renk, award, dude, fuck, hate, peo...  \n",
       "2               [real, tho, cartoon, cat, box, back]  \n",
       "3  [right, rain, stomach, hurt, it’, probabl, gho...  \n",
       "4  [licens, dad, joke, dad, tell, joke, home, dad...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = pd.read_json('./Data/Memes/memestitle_oc.json')\n",
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
